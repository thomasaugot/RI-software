import {  FC, useCallback, useEffect, useRef, useState } from 'react'
import AudioLevel from '../../../chatAudioLine/audioLevel'; // Importing the component to render audio levels
import RecordRTC from 'recordrtc'; // Importing RecordRTC library to record audio
import './chatAudioRecorder.scss' // Importing CSS styles for the component
import ChatTimer from '../../../chatTimer/chatTimer'; // Importing component to render recording timer
import { deleteAudioMessageIcon, recordingAudioIcon, sendMessageIcon } from '../../../../../assets/chatIcons'; // Importing icons to render buttons
import { chatAudioRecorderProps } from '../../../../../types/chats/audioMessageType'; // Importing props type for the component


// Defining props type for the component
const ChatAudioRecorder: FC<chatAudioRecorderProps> = ({isRecordingAudio, setIsRecordingAudio, handleAddAudioBlob, handleSubmit}) => {

  // Initializing state variables for the component
  const [blob, setBlob] = useState<Blob | null>(null); // Audio blob generated by RecordRTC
  const [levels, setLevels] = useState<number[]>([]); // Array to hold audio levels
  const [containerWidth, setContainerWidth] = useState(0); // Width of the container element
  const [timer, setTimer] = useState(0); // Time elapsed during recording
  const [isRec, setIsRec] = useState(false); // Flag to indicate if recording is currently in progress

  // Initializing ref variables for the component
  const recorder = useRef<RecordRTC | null>(null); // Ref variable for RecordRTC object
  const animationId = useRef<NodeJS.Timeout | null>(null); // Ref variable for animation ID
  const containerRef = useRef<null | HTMLDivElement >(null); // Ref variable for container element


  // Function to increment the recording timer
  const incrementTimer = useCallback(() => {
    setTimer((prevTimer) => prevTimer + 0.5);
  }, []);

  // Effect to set the width of the container element based on its current size
  useEffect(() => {
    if (containerRef.current) {
      const containerWidth = containerRef.current.clientWidth;
      if(containerWidth) {
        setContainerWidth(containerWidth);
      }
    }
  }, [levels]);

// Function to format the recording time in minutes and seconds
const formatTime = (seconds: number) => {
  let minutes = Math.floor(seconds / 60);
  let remainingSeconds = seconds % 60;
  let formattedMinutes = (minutes < 10) ? '0' + minutes : minutes;
  let formattedSeconds = (remainingSeconds < 10) ? '0' + remainingSeconds : remainingSeconds;
  return `${formattedMinutes}:${Math.floor(+formattedSeconds) > 10 ? Math.floor(+formattedSeconds) : `0${Math.floor(+formattedSeconds)}`}`;
}
  // Function to start recording audio
  const startRecording = async () => {
    const audio = await navigator.mediaDevices.getUserMedia({ audio: true });
    recorder.current = new RecordRTC(audio, { type: 'audio' });
    // Start recording the audio
    recorder.current.startRecording();

    const audioCtx = new AudioContext();
    const source = audioCtx.createMediaStreamSource(audio);
    const analyser = audioCtx.createAnalyser();

    // Connect the audio source to the analyser
    source.connect(analyser);

    // Set the minimum and maximum decibels for the analyser
    analyser.minDecibels = -90;
    analyser.maxDecibels = -10;
    // Set the FFT size for the analyser
    analyser.fftSize = 2048;

    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    const draw = () => {
       // Get the frequency data from the analyser
      analyser.getByteFrequencyData(dataArray);

      // Calculate the average value of the frequency data
      const sum = dataArray.reduce((acc, curr) => acc + curr, 0);
      const avg = sum / dataArray.length;

      // Scale the average value to a percentage value
      const scaledLevel = Math.floor((avg / 255) * 100);

      // Add the scaled level to the levels array
      setLevels((prevLevels) => [...prevLevels, scaledLevel]);
    };

    // Start drawing the audio levels every 500 milliseconds
    animationId.current =  setInterval(() => {
      draw()
      incrementTimer()
    }, 500);
  };

   // Function to stop recording audio
  const stopRecording = async () => {
     // Stop recording the audio and get the audio blob
    recorder.current?.stopRecording(() => {
      const blob = recorder.current?.getBlob();
      setBlob(blob as Blob);
      handleAddAudioBlob(blob as Blob, formatTime(timer))
    });

    // Clear the audio level animation interval
    clearInterval(animationId.current!);
    animationId.current = null;
  };

  // Start recording audio when the isRecording prop changes to true
  useEffect(() => {
    if(isRecordingAudio) {
      startRecording()
      setIsRec(true)
    }
  }, [isRecordingAudio])

  return (
    <>
      {!isRec && (
        <div className="delete-audio-message" onClick={() => {
          handleAddAudioBlob(null, null)
          setIsRecordingAudio(false)
        }}>
          {deleteAudioMessageIcon}
        </div>
      )}

      <ChatTimer timer={timer} isRec={isRec} blob={blob as Blob} />

      <div className="audio-recording-wrapper">
        {isRec ? (
          <div className="audio-recording-container"
               style={{ transform: `translateX(-${containerWidth - 31.4453125 * window.innerWidth / 100}px)` }}
               ref={containerRef}
          >
            {levels.map((level, index) => (
              <AudioLevel key={index} height={level} />
            ))}
          </div>
        ) : (
          levels.map((item, index) => <AudioLevel key={index} height={item} />)
        )}
      </div>

      <div className='recording-audio-button' onClick={(e) => {
        if (isRec) {
          stopRecording()
        } else {
          handleSubmit(null)
          setIsRecordingAudio(false)
        }
        setIsRec(false)
      }}>
        {isRec ? recordingAudioIcon : sendMessageIcon}
      </div>
    </>
  );

}

export default ChatAudioRecorder
